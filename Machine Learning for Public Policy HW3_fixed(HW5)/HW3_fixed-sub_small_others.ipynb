{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import date\n",
    "import re\n",
    "import warnings\n",
    "\n",
    "import feature_generation as fg\n",
    "import imputation as imp\n",
    "import evaluation as eva\n",
    "import train_test_split as tts\n",
    "import clf_define as clfd\n",
    "import data_util as util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = util.read_csv_data(r\"D:\\Project Data\\MLHW3\\projects_2012_2013.csv\", {}, parse_dates=['date_posted', 'datefullyfunded'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, we will like to define our features and classifiers in the dataframe. In order to maintain the as much patterns as possible, we will only drop the columns with ids which include too much distinguish categories (more than 51) and information like logitude and latitude which can be categorized better using city and state. The number 51 is selected due to the number of state categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "preserved_columns = []\n",
    "for column in data.columns:\n",
    "    if (data[column].dtype=='O') and (len(data[column].unique())<=51):\n",
    "        preserved_columns.append(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['school_state', 'school_metro', 'school_charter', 'school_magnet', 'teacher_prefix', 'primary_focus_subject', 'primary_focus_area', 'secondary_focus_subject', 'secondary_focus_area', 'resource_type', 'poverty_level', 'grade_level', 'eligible_double_your_impact_match']\n"
     ]
    }
   ],
   "source": [
    "print(preserved_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_features = ['total_price_including_optional_support', 'students_reached']\n",
    "categorical_features = set(preserved_columns) - set(continuous_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'teacher_prefix', 'resource_type', 'school_state', 'school_magnet', 'primary_focus_subject', 'secondary_focus_subject', 'school_charter', 'poverty_level', 'grade_level', 'eligible_double_your_impact_match', 'school_metro', 'secondary_focus_area', 'primary_focus_area'}\n"
     ]
    }
   ],
   "source": [
    "print(categorical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_price_including_optional_support</th>\n",
       "      <th>students_reached</th>\n",
       "      <th>teacher_prefix</th>\n",
       "      <th>resource_type</th>\n",
       "      <th>school_state</th>\n",
       "      <th>school_magnet</th>\n",
       "      <th>primary_focus_subject</th>\n",
       "      <th>secondary_focus_subject</th>\n",
       "      <th>school_charter</th>\n",
       "      <th>poverty_level</th>\n",
       "      <th>grade_level</th>\n",
       "      <th>eligible_double_your_impact_match</th>\n",
       "      <th>school_metro</th>\n",
       "      <th>secondary_focus_area</th>\n",
       "      <th>primary_focus_area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1498.61</td>\n",
       "      <td>31.0</td>\n",
       "      <td>Mrs.</td>\n",
       "      <td>Supplies</td>\n",
       "      <td>IL</td>\n",
       "      <td>f</td>\n",
       "      <td>Mathematics</td>\n",
       "      <td>Visual Arts</td>\n",
       "      <td>f</td>\n",
       "      <td>highest poverty</td>\n",
       "      <td>Grades PreK-2</td>\n",
       "      <td>f</td>\n",
       "      <td>urban</td>\n",
       "      <td>Music &amp; The Arts</td>\n",
       "      <td>Math &amp; Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>282.47</td>\n",
       "      <td>28.0</td>\n",
       "      <td>Mrs.</td>\n",
       "      <td>Books</td>\n",
       "      <td>CA</td>\n",
       "      <td>f</td>\n",
       "      <td>Civics &amp; Government</td>\n",
       "      <td>Literature &amp; Writing</td>\n",
       "      <td>f</td>\n",
       "      <td>highest poverty</td>\n",
       "      <td>Grades 3-5</td>\n",
       "      <td>t</td>\n",
       "      <td>urban</td>\n",
       "      <td>Literacy &amp; Language</td>\n",
       "      <td>History &amp; Civics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1012.38</td>\n",
       "      <td>56.0</td>\n",
       "      <td>Ms.</td>\n",
       "      <td>Technology</td>\n",
       "      <td>CA</td>\n",
       "      <td>f</td>\n",
       "      <td>Literacy</td>\n",
       "      <td>Social Sciences</td>\n",
       "      <td>f</td>\n",
       "      <td>high poverty</td>\n",
       "      <td>Grades 3-5</td>\n",
       "      <td>f</td>\n",
       "      <td>urban</td>\n",
       "      <td>History &amp; Civics</td>\n",
       "      <td>Literacy &amp; Language</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>175.33</td>\n",
       "      <td>23.0</td>\n",
       "      <td>Ms.</td>\n",
       "      <td>Books</td>\n",
       "      <td>NY</td>\n",
       "      <td>t</td>\n",
       "      <td>Literacy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>high poverty</td>\n",
       "      <td>Grades PreK-2</td>\n",
       "      <td>f</td>\n",
       "      <td>urban</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Literacy &amp; Language</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3591.11</td>\n",
       "      <td>150.0</td>\n",
       "      <td>Mrs.</td>\n",
       "      <td>Technology</td>\n",
       "      <td>NY</td>\n",
       "      <td>f</td>\n",
       "      <td>Literacy</td>\n",
       "      <td>Literature &amp; Writing</td>\n",
       "      <td>f</td>\n",
       "      <td>high poverty</td>\n",
       "      <td>Grades PreK-2</td>\n",
       "      <td>f</td>\n",
       "      <td>suburban</td>\n",
       "      <td>Literacy &amp; Language</td>\n",
       "      <td>Literacy &amp; Language</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   total_price_including_optional_support  students_reached teacher_prefix  \\\n",
       "0                                 1498.61              31.0           Mrs.   \n",
       "1                                  282.47              28.0           Mrs.   \n",
       "2                                 1012.38              56.0            Ms.   \n",
       "3                                  175.33              23.0            Ms.   \n",
       "4                                 3591.11             150.0           Mrs.   \n",
       "\n",
       "  resource_type school_state school_magnet primary_focus_subject  \\\n",
       "0      Supplies           IL             f           Mathematics   \n",
       "1         Books           CA             f   Civics & Government   \n",
       "2    Technology           CA             f              Literacy   \n",
       "3         Books           NY             t              Literacy   \n",
       "4    Technology           NY             f              Literacy   \n",
       "\n",
       "  secondary_focus_subject school_charter    poverty_level    grade_level  \\\n",
       "0             Visual Arts              f  highest poverty  Grades PreK-2   \n",
       "1    Literature & Writing              f  highest poverty     Grades 3-5   \n",
       "2         Social Sciences              f     high poverty     Grades 3-5   \n",
       "3                     NaN              f     high poverty  Grades PreK-2   \n",
       "4    Literature & Writing              f     high poverty  Grades PreK-2   \n",
       "\n",
       "  eligible_double_your_impact_match school_metro secondary_focus_area  \\\n",
       "0                                 f        urban     Music & The Arts   \n",
       "1                                 t        urban  Literacy & Language   \n",
       "2                                 f        urban     History & Civics   \n",
       "3                                 f        urban                  NaN   \n",
       "4                                 f     suburban  Literacy & Language   \n",
       "\n",
       "    primary_focus_area  \n",
       "0       Math & Science  \n",
       "1     History & Civics  \n",
       "2  Literacy & Language  \n",
       "3  Literacy & Language  \n",
       "4  Literacy & Language  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[continuous_features + list(categorical_features)].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We label 1 to the project which are not funded in 60 days right after they are posted, and label 0 to those who are funded in 60 days right after it is posted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['duration'] = data[\"datefullyfunded\"] - data[\"date_posted\"]\n",
    "data['classifier'] =  np.where(data['duration'] > pd.Timedelta('60 days'), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    1\n",
       "3    0\n",
       "4    1\n",
       "Name: classifier, dtype: int32"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = \"classifier\"\n",
    "data[\"classifier\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then move on to split the dataframe to train and test sets with rolling windows stratefy in this case. I split the dataframe with time unit of half years cutoff which is at date 6/30 and 12/31. For every training data set, there will remain 60 days gap for the result (label) of the outcome (classifier) to be observed. The testing set will be set as half year (might be shorter in the last test set) right after the gap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "half_year_stamp = [(1,1), (7,1)]\n",
    "start_date = pd.Timestamp('2012-01-01 00:00:00')\n",
    "end_date = pd.Timestamp('2014-01-01 00:00:00')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "time_cutoff lists includes the start date, one day after the end dates and other cutoff dates, time interval will be defined as the date between them (including the lower but not include the upper bound)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Timestamp('2012-01-01 00:00:00'), Timestamp('2012-07-01 00:00:00'), Timestamp('2013-01-01 00:00:00'), Timestamp('2013-07-01 00:00:00'), Timestamp('2014-01-01 00:00:00')]\n"
     ]
    }
   ],
   "source": [
    "time_cutoffs = tts.gen_time_cuts(start_date, end_date, half_year_stamp)\n",
    "print(sorted(time_cutoffs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I use define_time_variables to create the indicators for rolling window split in this case, taking waiting times (60 days) into account. All train dataframe starts in 2012-01-01 but the testing data starts at 2012-07-01 + (60 days), 2013-01-01 + (60 days), 2013-07-01 + (60 days) respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = tts.define_time_variables(data, pd.Timedelta('183 days'), pd.Timedelta('60 days'), \"date_posted\", \"datefullyfunded\", start_date, end_date, half_year_stamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69180   2012-01-01\n",
       "32005   2012-01-01\n",
       "38220   2012-01-01\n",
       "74297   2012-01-01\n",
       "21950   2012-01-01\n",
       "Name: date_posted, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data[\"tmp_label0\"] == \"train\"][\"date_posted\"].sort_values(ascending=True).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16332    2012-08-30\n",
       "60107    2012-08-30\n",
       "71880    2012-08-30\n",
       "107093   2012-08-30\n",
       "107156   2012-08-30\n",
       "Name: date_posted, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data[\"tmp_label0\"] == \"test\"][\"date_posted\"].sort_values(ascending=True).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72487    2012-01-01\n",
       "63421    2012-01-01\n",
       "117377   2012-01-01\n",
       "62941    2012-01-01\n",
       "117198   2012-01-01\n",
       "Name: date_posted, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data[\"tmp_label1\"] == \"train\"][\"date_posted\"].sort_values(ascending=True).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "121525   2013-03-02\n",
       "37673    2013-03-02\n",
       "3158     2013-03-02\n",
       "108509   2013-03-02\n",
       "30275    2013-03-02\n",
       "Name: date_posted, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data[\"tmp_label1\"] == \"test\"][\"date_posted\"].sort_values(ascending=True).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63675    2012-01-01\n",
       "114946   2012-01-01\n",
       "48094    2012-01-01\n",
       "50966    2012-01-01\n",
       "107459   2012-01-01\n",
       "Name: date_posted, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data[\"tmp_label2\"] == \"train\"][\"date_posted\"].sort_values(ascending=True).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66491    2013-08-30\n",
       "121728   2013-08-30\n",
       "15134    2013-08-30\n",
       "111442   2013-08-30\n",
       "93247    2013-08-30\n",
       "Name: date_posted, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data[\"tmp_label2\"] == \"test\"][\"date_posted\"].sort_values(ascending=True).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is then be splitted according to the time_split_indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_split_indicators = [\"tmp_label0\", \"tmp_label1\", \"tmp_label2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = tts.rolling_window_split(data, time_split_indicators, list(categorical_features) + continuous_features, classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We than move on to the imputation of missing values in the data of each sub set, we used the trained infromation in the training dataframe is used it in the transformation in the corresponding test dataframe. We will used different strategies with different missing values in the dataframe. For the categorical variables, we will use a \"unknown\" category to replace the unknown values. (Using fill_unknown) For the continuous variable, we will use the group mean of the training data to impute both training and testing dataframe. (Using fill_na_mean) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe several missing values in the given dataframe after rolling window split, we do not want to include classifier in the imputation since labeling unknown classification will be problematic with distribution taht we are not sure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing in training tmp_label0\n",
      "{'teacher_prefix': (0, 26386), 'resource_type': (2, 26386), 'school_state': (0, 26386), 'school_magnet': (0, 26386), 'primary_focus_subject': (2, 26386), 'secondary_focus_subject': (8524, 26386), 'school_charter': (0, 26386), 'poverty_level': (0, 26386), 'grade_level': (1, 26386), 'eligible_double_your_impact_match': (0, 26386), 'school_metro': (2643, 26386), 'secondary_focus_area': (8524, 26386), 'primary_focus_area': (2, 26386), 'students_reached': (4, 26386), 'total_price_including_optional_support': (0, 26386)}\n",
      "missing in testing tmp_label0\n",
      "{'teacher_prefix': (0, 33357), 'resource_type': (5, 33357), 'school_state': (0, 33357), 'school_magnet': (0, 33357), 'primary_focus_subject': (4, 33357), 'secondary_focus_subject': (11045, 33357), 'school_charter': (0, 33357), 'poverty_level': (0, 33357), 'grade_level': (2, 33357), 'eligible_double_your_impact_match': (0, 33357), 'school_metro': (4015, 33357), 'secondary_focus_area': (11045, 33357), 'primary_focus_area': (4, 33357), 'students_reached': (22, 33357), 'total_price_including_optional_support': (0, 33357)}\n",
      "           \n",
      "missing in training tmp_label2\n",
      "{'teacher_prefix': (0, 80809), 'resource_type': (17, 80809), 'school_state': (0, 80809), 'school_magnet': (0, 80809), 'primary_focus_subject': (15, 80809), 'secondary_focus_subject': (26340, 80809), 'school_charter': (0, 80809), 'poverty_level': (0, 80809), 'grade_level': (3, 80809), 'eligible_double_your_impact_match': (0, 80809), 'school_metro': (9412, 80809), 'secondary_focus_area': (26340, 80809), 'primary_focus_area': (15, 80809), 'students_reached': (59, 80809), 'total_price_including_optional_support': (0, 80809)}\n",
      "missing in testing tmp_label2\n",
      "{'teacher_prefix': (0, 32994), 'resource_type': (0, 32994), 'school_state': (0, 32994), 'school_magnet': (0, 32994), 'primary_focus_subject': (0, 32994), 'secondary_focus_subject': (10442, 32994), 'school_charter': (0, 32994), 'poverty_level': (0, 32994), 'grade_level': (0, 32994), 'eligible_double_your_impact_match': (0, 32994), 'school_metro': (4250, 32994), 'secondary_focus_area': (10442, 32994), 'primary_focus_area': (0, 32994), 'students_reached': (0, 32994), 'total_price_including_optional_support': (0, 32994)}\n",
      "           \n",
      "missing in training tmp_label1\n",
      "{'teacher_prefix': (0, 59224), 'resource_type': (2, 59224), 'school_state': (0, 59224), 'school_magnet': (0, 59224), 'primary_focus_subject': (2, 59224), 'secondary_focus_subject': (19574, 59224), 'school_charter': (0, 59224), 'poverty_level': (0, 59224), 'grade_level': (1, 59224), 'eligible_double_your_impact_match': (0, 59224), 'school_metro': (6615, 59224), 'secondary_focus_area': (19574, 59224), 'primary_focus_area': (2, 59224), 'students_reached': (4, 59224), 'total_price_including_optional_support': (0, 59224)}\n",
      "missing in testing tmp_label1\n",
      "{'teacher_prefix': (0, 24857), 'resource_type': (10, 24857), 'school_state': (0, 24857), 'school_magnet': (0, 24857), 'primary_focus_subject': (9, 24857), 'secondary_focus_subject': (8033, 24857), 'school_charter': (0, 24857), 'poverty_level': (0, 24857), 'grade_level': (0, 24857), 'eligible_double_your_impact_match': (0, 24857), 'school_metro': (3337, 24857), 'secondary_focus_area': (8033, 24857), 'primary_focus_area': (9, 24857), 'students_reached': (32, 24857), 'total_price_including_optional_support': (0, 24857)}\n",
      "           \n"
     ]
    }
   ],
   "source": [
    "for idx, dat in data_dict.items():\n",
    "    train_X, train_y, test_X, test_y = dat\n",
    "    print(\"missing in training \" + idx)\n",
    "    print(imp.summarize_missing_values(train_X))\n",
    "    print(\"missing in testing \" + idx)\n",
    "    print(imp.summarize_missing_values(test_X))\n",
    "    print(\"           \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_data_dict = {}\n",
    "for idx, dat in data_dict.items():\n",
    "    train_X, train_y, test_X, test_y = dat\n",
    "    train_X, test_X = imp.fill_na_mean(train_X, test_X, continuous_features)\n",
    "    train_X, test_X = imp.fill_unknown(train_X, test_X, categorical_features)\n",
    "    imp_data_dict[idx] = [train_X, train_y, test_X, test_y]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that after the imputation the new_data_dict contains no missing values in the training and testing subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing in training tmp_label0\n",
      "{'teacher_prefix': (0, 26386), 'resource_type': (0, 26386), 'school_state': (0, 26386), 'school_magnet': (0, 26386), 'primary_focus_subject': (0, 26386), 'secondary_focus_subject': (0, 26386), 'school_charter': (0, 26386), 'poverty_level': (0, 26386), 'grade_level': (0, 26386), 'eligible_double_your_impact_match': (0, 26386), 'school_metro': (0, 26386), 'secondary_focus_area': (0, 26386), 'primary_focus_area': (0, 26386), 'students_reached': (0, 26386), 'total_price_including_optional_support': (0, 26386)}\n",
      "missing in testing tmp_label0\n",
      "{'teacher_prefix': (0, 33357), 'resource_type': (0, 33357), 'school_state': (0, 33357), 'school_magnet': (0, 33357), 'primary_focus_subject': (0, 33357), 'secondary_focus_subject': (0, 33357), 'school_charter': (0, 33357), 'poverty_level': (0, 33357), 'grade_level': (0, 33357), 'eligible_double_your_impact_match': (0, 33357), 'school_metro': (0, 33357), 'secondary_focus_area': (0, 33357), 'primary_focus_area': (0, 33357), 'students_reached': (0, 33357), 'total_price_including_optional_support': (0, 33357)}\n",
      "           \n",
      "missing in training tmp_label2\n",
      "{'teacher_prefix': (0, 80809), 'resource_type': (0, 80809), 'school_state': (0, 80809), 'school_magnet': (0, 80809), 'primary_focus_subject': (0, 80809), 'secondary_focus_subject': (0, 80809), 'school_charter': (0, 80809), 'poverty_level': (0, 80809), 'grade_level': (0, 80809), 'eligible_double_your_impact_match': (0, 80809), 'school_metro': (0, 80809), 'secondary_focus_area': (0, 80809), 'primary_focus_area': (0, 80809), 'students_reached': (0, 80809), 'total_price_including_optional_support': (0, 80809)}\n",
      "missing in testing tmp_label2\n",
      "{'teacher_prefix': (0, 32994), 'resource_type': (0, 32994), 'school_state': (0, 32994), 'school_magnet': (0, 32994), 'primary_focus_subject': (0, 32994), 'secondary_focus_subject': (0, 32994), 'school_charter': (0, 32994), 'poverty_level': (0, 32994), 'grade_level': (0, 32994), 'eligible_double_your_impact_match': (0, 32994), 'school_metro': (0, 32994), 'secondary_focus_area': (0, 32994), 'primary_focus_area': (0, 32994), 'students_reached': (0, 32994), 'total_price_including_optional_support': (0, 32994)}\n",
      "           \n",
      "missing in training tmp_label1\n",
      "{'teacher_prefix': (0, 59224), 'resource_type': (0, 59224), 'school_state': (0, 59224), 'school_magnet': (0, 59224), 'primary_focus_subject': (0, 59224), 'secondary_focus_subject': (0, 59224), 'school_charter': (0, 59224), 'poverty_level': (0, 59224), 'grade_level': (0, 59224), 'eligible_double_your_impact_match': (0, 59224), 'school_metro': (0, 59224), 'secondary_focus_area': (0, 59224), 'primary_focus_area': (0, 59224), 'students_reached': (0, 59224), 'total_price_including_optional_support': (0, 59224)}\n",
      "missing in testing tmp_label1\n",
      "{'teacher_prefix': (0, 24857), 'resource_type': (0, 24857), 'school_state': (0, 24857), 'school_magnet': (0, 24857), 'primary_focus_subject': (0, 24857), 'secondary_focus_subject': (0, 24857), 'school_charter': (0, 24857), 'poverty_level': (0, 24857), 'grade_level': (0, 24857), 'eligible_double_your_impact_match': (0, 24857), 'school_metro': (0, 24857), 'secondary_focus_area': (0, 24857), 'primary_focus_area': (0, 24857), 'students_reached': (0, 24857), 'total_price_including_optional_support': (0, 24857)}\n",
      "           \n"
     ]
    }
   ],
   "source": [
    "for idx, dat in imp_data_dict.items():\n",
    "    train_X, train_y, test_X, test_y = dat\n",
    "    print(\"missing in training \" + idx)\n",
    "    print(imp.summarize_missing_values(train_X))\n",
    "    print(\"missing in testing \" + idx)\n",
    "    print(imp.summarize_missing_values(test_X))\n",
    "    print(\"           \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After I impute the missing values, I move on to feature generations. In this process, the features generated in the training dataframe have to be consistant to the features in testing dataframe. All categorical variables in the selected features will be transformed to binary features and all continuous variables will be transformed to scaled continuous using MaxMinScale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_data_dict = {}\n",
    "for idx, dat in imp_data_dict.items():\n",
    "    train_X, train_y, test_X, test_y = dat\n",
    "    train_X, test_X = fg.min_max_transformation(train_X, test_X, continuous_features)\n",
    "    ft_data_dict[idx] = [train_X, train_y, test_X, test_y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_data_dict2 = {}\n",
    "for idx, dat in ft_data_dict.items():\n",
    "    train_X, train_y, test_X, test_y = dat\n",
    "    for cat_column in categorical_features:\n",
    "        train_X, test_X = fg.category_to_binary(train_X, test_X, cat_column)\n",
    "    ft_data_dict2[idx] = [train_X, train_y, test_X, test_y]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then define the final dictionary of data using for machine learning pipeline as ft_data_dict2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = ft_data_dict2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then begin the training and evaluation process of the data, we will use different methods, different proportion of the populations we might concern, and also conduct cross_validation in the following training and evaluation process. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the time concern of training models, I will define the models with differnt priorities. Low priority model will only be trained in the simple grid, the medium priority models will be trained in simple and small grid, and high priority models will the trained in all of the grids. The model with their corresponding priorities are presented as the following.\n",
    "1. Low priority: KNN, Naive Bayes, SVM\n",
    "2. Medium priority: Bagging, Adaboost, Gradient Boosting, Extra Trees\n",
    "3. High priority: Decision Tree, Random Forest, Logistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in the threshold column in performance matrix, the value is represents the percentile of the predicted probability from the given classifiers. I sort the values of the score (or probability) and define the threshold with the given percentile, any score which is higher than the threshold will then be classified as 1. The design is corresponding to the x-axis in precision-recall curve (\"percent of population labelled 1 in prediction\") when we care about the percent of population with the highest risks.\n",
    "0. percentile = 100% , percent of population labelled 1 in prediction: 0%\n",
    "1. percentile = 99% , percent of population labelled 1 in prediction: 1%\n",
    "2. percentile = 98% , percent of population labelled 1 in prediction: 2%\n",
    "3. percentile = 95% , percent of population labelled 1 in prediction: 5%\n",
    "4. percentile = 90% , percent of population labelled 1 in prediction: 10%\n",
    "5. percentile = 80% , percent of population labelled 1 in prediction: 20%\n",
    "6. percentile = 70% , percent of population labelled 1 in prediction: 30%\n",
    "7. percentile = 60% , percent of population labelled 1 in prediction: 40%\n",
    "8. percentile = 50% , percent of population labelled 1 in prediction: 50%\n",
    "9. percentile = 0% , percent of population labelled 1 in prediction: 100%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that if percent of population labelled 1 in prediction is 100%, we can estimate the baseline prediction of precision with base strategy to predict 1 for all rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model below provide the full training for all the model list in the grids. The performance matrix contains the information method used, parameters used, evaluation performance including \"accuracy\", \"f1\", \"recall\", \"precision\", \"AUC_ROC\", and the corresponding temporal subset passing in. The function can also be specified to plot precision and recall curve the provide the whole pictures of every thresholds (0.99, 0.98, 0.95, 0.9, 0.8, 0.7, 0.6, 0.5) using in classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "cross_val_performance_small = clfd.cross_validate_performance(clfd.clfs, clfd.small, data_dict, [0.99, 0.98, 0.95, 0.9, 0.8, 0.7, 0.6, 0.5], \\\n",
    "                                [\"accuracy\", \"f1\", \"recall\", \"precision\", \"AUC_ROC\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "cross_val_performance_small.to_pickle(\"cross_val_performance_small_final\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = cross_val_performance_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "method                                                      decision_tree\n",
       "accuracy                                                         0.713706\n",
       "f1                                                               0.117856\n",
       "recall                                                          0.0690523\n",
       "precision                                                        0.401911\n",
       "AUC_ROC                                                           0.64889\n",
       "threshold                                                            0.95\n",
       "parameters              decision_tree with parameters : {'splitter': '...\n",
       "cross_validate_index                                           tmp_label2\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ct[(ct.method==\"decision_tree\") & (ct.cross_validate_index==\"tmp_label2\") & (ct.threshold==0.95)].sort_values(by=\"precision\", ascending=False).iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "method                                                      random_forest\n",
       "accuracy                                                         0.715585\n",
       "f1                                                               0.130145\n",
       "recall                                                          0.0768221\n",
       "precision                                                        0.425455\n",
       "AUC_ROC                                                          0.630976\n",
       "threshold                                                            0.95\n",
       "parameters              random_forest with parameters : {'n_jobs': 2, ...\n",
       "cross_validate_index                                           tmp_label2\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ct[(ct.method==\"random_forest\") & (ct.cross_validate_index==\"tmp_label2\") & (ct.threshold==0.95)].sort_values(by=\"precision\", ascending=False).iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "method                                                          logistics\n",
       "accuracy                                                         0.714857\n",
       "f1                                                                0.12792\n",
       "recall                                                          0.0755089\n",
       "precision                                                        0.418182\n",
       "AUC_ROC                                                          0.565274\n",
       "threshold                                                            0.95\n",
       "parameters              logistics with parameters : {'fit_intercept': ...\n",
       "cross_validate_index                                           tmp_label2\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ct[(ct.method==\"logistics\") & (ct.cross_validate_index==\"tmp_label2\") & (ct.threshold==0.95)].sort_values(by=\"precision\", ascending=False).iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "method                                                                 ET\n",
       "accuracy                                                         0.707038\n",
       "f1                                                               0.104004\n",
       "recall                                                           0.061392\n",
       "precision                                                            0.34\n",
       "AUC_ROC                                                          0.563977\n",
       "threshold                                                            0.95\n",
       "parameters              ET with parameters : {'n_jobs': -1, 'class_wei...\n",
       "cross_validate_index                                           tmp_label2\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ct[(ct.method==\"ET\") & (ct.cross_validate_index==\"tmp_label2\") & (ct.threshold==0.95)].sort_values(by=\"precision\", ascending=False).iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "method                                                      gradientboost\n",
       "accuracy                                                         0.723131\n",
       "f1                                                             0.00283812\n",
       "recall                                                         0.00142263\n",
       "precision                                                        0.565217\n",
       "AUC_ROC                                                           0.52255\n",
       "threshold                                                            0.95\n",
       "parameters              gradientboost with parameters : {'n_estimators...\n",
       "cross_validate_index                                           tmp_label2\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ct[(ct.method==\"gradientboost\") & (ct.cross_validate_index==\"tmp_label2\") & (ct.threshold==0.95)].sort_values(by=\"precision\", ascending=False).iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "method                                                           adaboost\n",
       "accuracy                                                         0.713584\n",
       "f1                                                               0.124027\n",
       "recall                                                          0.0732108\n",
       "precision                                                        0.405455\n",
       "AUC_ROC                                                          0.634503\n",
       "threshold                                                            0.95\n",
       "parameters              adaboost with parameters : {'n_estimators': 10...\n",
       "cross_validate_index                                           tmp_label2\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ct[(ct.method==\"adaboost\") & (ct.cross_validate_index==\"tmp_label2\") & (ct.threshold==0.95)].sort_values(by=\"precision\", ascending=False).iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "method                                                            bagging\n",
       "accuracy                                                         0.714615\n",
       "f1                                                               0.127178\n",
       "recall                                                          0.0750711\n",
       "precision                                                        0.415758\n",
       "AUC_ROC                                                          0.566985\n",
       "threshold                                                            0.95\n",
       "parameters              bagging with parameters : {'base_estimator__C'...\n",
       "cross_validate_index                                           tmp_label2\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ct[(ct.method==\"bagging\") & (ct.cross_validate_index==\"tmp_label2\") & (ct.threshold==0.95)].sort_values(by=\"precision\", ascending=False).iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "other = {'SVM' :{'C' :[0.001,0.01,0.1,1,10],'kernel':['linear']},\n",
    "'KNN' :{'n_neighbors': [1,5,10],'weights': ['distance'],'algorithm': ['auto']}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "cross_val_performance_other = clfd.cross_validate_performance(clfd.clfs, other, data_dict, [0.99, 0.98, 0.95, 0.9, 0.8, 0.7, 0.6, 0.5], \\\n",
    "                                [\"accuracy\", \"f1\", \"recall\", \"precision\", \"AUC_ROC\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_performance_other.to_pickle(\"cross_val_performance_other_final\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct2 = cross_val_performance_other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "method                                                                KNN\n",
       "accuracy                                                         0.707886\n",
       "f1                                                                 0.1066\n",
       "recall                                                          0.0629241\n",
       "precision                                                        0.348485\n",
       "AUC_ROC                                                          0.544768\n",
       "threshold                                                            0.95\n",
       "parameters              KNN with parameters : {'n_neighbors': 10, 'lea...\n",
       "cross_validate_index                                           tmp_label2\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ct2[(ct2.method==\"KNN\") & (ct2.cross_validate_index==\"tmp_label2\") & (ct2.threshold==0.95)].sort_values(by=\"precision\", ascending=False).iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "method                                                                SVM\n",
       "accuracy                                                         0.702431\n",
       "f1                                                              0.0899147\n",
       "recall                                                          0.0530751\n",
       "precision                                                        0.293939\n",
       "AUC_ROC                                                          0.503502\n",
       "threshold                                                            0.95\n",
       "parameters              SVM with parameters : {'decision_function_shap...\n",
       "cross_validate_index                                           tmp_label2\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ct2[(ct2.method==\"SVM\") & (ct2.cross_validate_index==\"tmp_label2\") & (ct2.threshold==0.95)].sort_values(by=\"precision\", ascending=False).iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py3.5]",
   "language": "python",
   "name": "conda-env-py3.5-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

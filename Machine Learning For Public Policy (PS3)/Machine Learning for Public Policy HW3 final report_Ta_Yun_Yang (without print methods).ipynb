{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import date\n",
    "import re\n",
    "\n",
    "import train_test_split as tts\n",
    "import evaluation as eva\n",
    "import data_util as util\n",
    "import feature_selection_missing_data as femd\n",
    "import do\n",
    "\n",
    "import decision_tree\n",
    "import logistic\n",
    "import svm\n",
    "import knn\n",
    "import boosting\n",
    "import bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = util.read_csv_data(\"projects_2012_2013.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'date_posted': (0, 124976),\n",
       " 'datefullyfunded': (0, 124976),\n",
       " 'eligible_double_your_impact_match': (0, 124976),\n",
       " 'grade_level': (3, 124976),\n",
       " 'poverty_level': (0, 124976),\n",
       " 'primary_focus_area': (15, 124976),\n",
       " 'primary_focus_subject': (15, 124976),\n",
       " 'projectid': (0, 124976),\n",
       " 'resource_type': (17, 124976),\n",
       " 'school_charter': (0, 124976),\n",
       " 'school_city': (0, 124976),\n",
       " 'school_county': (0, 124976),\n",
       " 'school_district': (172, 124976),\n",
       " 'school_latitude': (0, 124976),\n",
       " 'school_longitude': (0, 124976),\n",
       " 'school_magnet': (0, 124976),\n",
       " 'school_metro': (15224, 124976),\n",
       " 'school_ncesid': (9233, 124976),\n",
       " 'school_state': (0, 124976),\n",
       " 'schoolid': (0, 124976),\n",
       " 'secondary_focus_area': (40556, 124976),\n",
       " 'secondary_focus_subject': (40556, 124976),\n",
       " 'students_reached': (59, 124976),\n",
       " 'teacher_acctid': (0, 124976),\n",
       " 'teacher_prefix': (0, 124976),\n",
       " 'total_price_including_optional_support': (0, 124976)}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "femd.summarize_missing_values(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the fact the columns which contain the missing values are categorical, using origin method to fill the missing in column mean is not appropriate. Therefore, I use the most frequent value in given columns instead to fill in the missing value, which are less restricted to the type of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = femd.fill_na_freq(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'date_posted': (0, 124976),\n",
       " 'datefullyfunded': (0, 124976),\n",
       " 'eligible_double_your_impact_match': (0, 124976),\n",
       " 'grade_level': (0, 124976),\n",
       " 'poverty_level': (0, 124976),\n",
       " 'primary_focus_area': (0, 124976),\n",
       " 'primary_focus_subject': (0, 124976),\n",
       " 'projectid': (0, 124976),\n",
       " 'resource_type': (0, 124976),\n",
       " 'school_charter': (0, 124976),\n",
       " 'school_city': (0, 124976),\n",
       " 'school_county': (0, 124976),\n",
       " 'school_district': (0, 124976),\n",
       " 'school_latitude': (0, 124976),\n",
       " 'school_longitude': (0, 124976),\n",
       " 'school_magnet': (0, 124976),\n",
       " 'school_metro': (0, 124976),\n",
       " 'school_ncesid': (0, 124976),\n",
       " 'school_state': (0, 124976),\n",
       " 'schoolid': (0, 124976),\n",
       " 'secondary_focus_area': (0, 124976),\n",
       " 'secondary_focus_subject': (0, 124976),\n",
       " 'students_reached': (0, 124976),\n",
       " 'teacher_acctid': (0, 124976),\n",
       " 'teacher_prefix': (0, 124976),\n",
       " 'total_price_including_optional_support': (0, 124976)}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "femd.summarize_missing_values(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the missing value is filled, the summary statistics that all the data I am going to use is complete right now. Then we move on to define features and classifiers. First of all, we exclude personal and geographical identification recods of the variables and focus on the features representing the characteristics of the projects. We find out that lots of the features are categorical in this case. In order to make use of these features, we thransform them to binary variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"school_charter\", \"school_magnet\", \"primary_focus_subject\", \"primary_focus_area\", \"secondary_focus_subject\",\n",
    "           \"secondary_focus_area\", \"resource_type\", \"poverty_level\", \"grade_level\", 'eligible_double_your_impact_match',\n",
    "           'total_price_including_optional_support', 'students_reached']\n",
    "cat_features = [\"school_charter\", \"school_magnet\", \"primary_focus_subject\", \"primary_focus_area\", \"secondary_focus_subject\",\n",
    "           \"secondary_focus_area\", \"resource_type\", \"poverty_level\", \"grade_level\", 'eligible_double_your_impact_match']\n",
    "selected_columns = [\"school_charter\", \"school_magnet\", \"primary_focus_subject\", \"primary_focus_area\", \"secondary_focus_subject\",\n",
    "           \"secondary_focus_area\", \"resource_type\", \"poverty_level\", \"grade_level\", 'eligible_double_your_impact_match',\n",
    "           'date_posted', 'datefullyfunded', 'total_price_including_optional_support', 'students_reached']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[selected_columns]\n",
    "for feature in cat_features:\n",
    "    data = util.category_to_binary(data, feature)\n",
    "data = data[data.columns[10:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_features = data.columns[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_date(date_string):\n",
    "    full_date = re.findall(\"([0-9]*)/([0-9]*)/([0-9]*)\", date_string)[0]\n",
    "    i_year, i_month, i_day = int(\"20\" + full_date[2]), int(full_date[0]), int(full_date[1])\n",
    "    return date(i_year, i_month, i_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"date_posted\"] = data.apply(lambda x: define_date(x[\"date_posted\"]), axis=1)\n",
    "data['datefullyfunded'] = data.apply(lambda x: define_date(x['datefullyfunded']), axis=1)\n",
    "data[\"accept_day\"] = data.apply(lambda x: (x['datefullyfunded'] - x[\"date_posted\"]).days, axis=1)\n",
    "data[\"classifier\"] = 0\n",
    "data.loc[data[\"accept_day\"] > 60, \"classifier\"] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considering the scale may be effective in svm and logistics models, I normalized the continuous variables in the dataset with function normalization_column in data_util.py file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns = ['total_price_including_optional_support', 'students_reached']\n",
    "for column in numerical_columns:\n",
    "    data = util.normalization_column(data, column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_setter(time_object):\n",
    "    time = 0\n",
    "    if (time_object - date(2012, 6, 30)).days > 0:\n",
    "        if (time_object - date(2012, 12, 31)).days > 0:\n",
    "            if (time_object - date(2013, 6, 30)).days > 0:\n",
    "                time = 3\n",
    "            else:\n",
    "                time = 2         \n",
    "        else:\n",
    "            time = 1\n",
    "\n",
    "    return time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"time\"] = data.apply(lambda x: time_setter(x[\"date_posted\"]), axis=1)\n",
    "classifier = 'classifier'\n",
    "time_index = \"time\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2881353219818205"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data[\"classifier\"]==1].shape[0] / data.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The total number of features is 92 in this case, I am applying select_K_best_features function from featue_selection_missing_data.py to select the k features which contain the most variance in the pool of features. In this analysis, the number of k will be set to 30."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Kfeatures = list(femd.select_K_best_features(data, final_features, classifier, k=30)[1].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = tts.rolling_window_split(data, time_index, Kfeatures, classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_list = [0.01, 0.02, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "opt = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy for models\n",
    "decision_tree_accuracy = do.cross_validate_performance(data_dict, \"decision_tree\", opt, \"accuracy\", threshold_list)\n",
    "random_forest_accuracy = do.cross_validate_performance(data_dict, \"random_forest\", opt, \"accuracy\", threshold_list)\n",
    "svm_accuracy = do.cross_validate_performance(data_dict, \"svm\", opt, \"accuracy\", threshold_list)\n",
    "logistics_accuracy = do.cross_validate_performance(data_dict, \"logistics\", opt, \"accuracy\", threshold_list)\n",
    "knn_accuracy = do.cross_validate_performance(data_dict, \"knn\", opt, \"accuracy\", threshold_list)\n",
    "\n",
    "\n",
    "# precision for models\n",
    "decision_tree_precision = do.cross_validate_performance(data_dict, \"decision_tree\", opt, \"precision\", threshold_list)\n",
    "random_forest_precision = do.cross_validate_performance(data_dict, \"random_forest\", opt, \"precision\", threshold_list)\n",
    "svm_precision = do.cross_validate_performance(data_dict, \"svm\", opt, \"precision\", threshold_list)\n",
    "logistics_precision = do.cross_validate_performance(data_dict, \"logistics\", opt, \"precision\", threshold_list)\n",
    "knn_precision = do.cross_validate_performance(data_dict, \"knn\", opt, \"precision\", threshold_list)\n",
    "\n",
    "\n",
    "# recall for models\n",
    "decision_tree_recall = do.cross_validate_performance(data_dict, \"decision_tree\", opt, \"recall\", threshold_list)\n",
    "random_forest_recall = do.cross_validate_performance(data_dict, \"random_forest\", opt, \"recall\", threshold_list)\n",
    "svm_recall = do.cross_validate_performance(data_dict, \"svm\", opt, \"recall\", threshold_list)\n",
    "logistics_recall = do.cross_validate_performance(data_dict, \"logistics\", opt, \"recall\", threshold_list)\n",
    "knn_recall = do.cross_validate_performance(data_dict, \"knn\", opt, \"recall\", threshold_list)\n",
    "\n",
    "\n",
    "# f1 for models\n",
    "decision_tree_f1 = do.cross_validate_performance(data_dict, \"decision_tree\", opt, \"f1\", threshold_list)\n",
    "random_forest_f1 = do.cross_validate_performance(data_dict, \"random_forest\", opt, \"f1\", threshold_list)\n",
    "svm_f1 = do.cross_validate_performance(data_dict, \"svm\", opt, \"f1\", threshold_list)\n",
    "logistics_f1 = do.cross_validate_performance(data_dict, \"logistics\", opt, \"f1\", threshold_list)\n",
    "knn_f1 = do.cross_validate_performance(data_dict, \"knn\", opt, \"f1\", threshold_list)\n",
    "\n",
    "\n",
    "# AUC_ROC for models\n",
    "decision_tree_AUC_ROC = do.cross_validate_performance(data_dict, \"decision_tree\", opt, \"AUC_ROC\", threshold_list)\n",
    "random_forest_AUC_ROC = do.cross_validate_performance(data_dict, \"random_forest\", opt, \"AUC_ROC\", threshold_list)\n",
    "svm_AUC_ROC = do.cross_validate_performance(data_dict, \"svm\", opt, \"AUC_ROC\", threshold_list)\n",
    "logistics_AUC_ROC = do.cross_validate_performance(data_dict, \"logistics\", opt, \"AUC_ROC\", threshold_list)\n",
    "knn_AUC_ROC = do.cross_validate_performance(data_dict, \"knn\", opt, \"AUC_ROC\", threshold_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that svm models might encounters warning that solver terminated early with max_iter=1000 even with scaled features. This may due to the fact that svm package face problems of computational complexity (with non-linear svc) when the sample size is greater than 10000. Since the performance is not influenced a lot, we might assume that the model is on the track of convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cross_validate_performance function in do.py file, prevides a general pipeline to evaluate the performance of each models with different hyper-parameter passing in. The function will automatically find the best threshold which produce the highest score of the given evaluation. The list of threshold I am testing with is the percentile [0.01, 0.02, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5] in the probability distribution of the predicted probabilities. The model also take cross-validated method into account and return the individual performances and average performance for the subsets of train-test split with given combination of hyper-parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, we compare the evaluation method using accuracy with different machine learning models and take the combination with the highest performance, and find out that knn has the highest accuracy score. However, accuracy is not a appropriate measurement in our analysis since it does not have a clear distinguision on where the accuracy comes from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "criterion                   entropy\n",
       "splitter                       best\n",
       "max_depth                        10\n",
       "avg_performance            0.601298\n",
       "performance_temp_model0    0.591023\n",
       "performance_temp_model1    0.613667\n",
       "performance_temp_model2    0.599203\n",
       "Name: 30, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decision_tree_accuracy.sort_values(by=\"avg_performance\", ascending=False).iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "criterion                   entropy\n",
       "n_estimators                     15\n",
       "max_depth                        10\n",
       "avg_performance            0.601764\n",
       "performance_temp_model0    0.590322\n",
       "performance_temp_model1     0.61237\n",
       "performance_temp_model2    0.602599\n",
       "Name: 50, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest_accuracy.sort_values(by=\"avg_performance\", ascending=False).iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "kernel                       linear\n",
       "C                                10\n",
       "avg_performance            0.561581\n",
       "performance_temp_model0    0.523357\n",
       "performance_temp_model1     0.57665\n",
       "performance_temp_model2    0.584735\n",
       "Name: 3, dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_accuracy.sort_values(by=\"avg_performance\", ascending=False).iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "penalty                          l1\n",
       "C                                 1\n",
       "avg_performance            0.584306\n",
       "performance_temp_model0    0.578172\n",
       "performance_temp_model1    0.584804\n",
       "performance_temp_model2    0.589943\n",
       "Name: 2, dtype: object"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistics_accuracy.sort_values(by=\"avg_performance\", ascending=False).iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "metric                     euclidean\n",
       "n_neighbors                       92\n",
       "avg_performance             0.602392\n",
       "performance_temp_model0     0.589835\n",
       "performance_temp_model1     0.611073\n",
       "performance_temp_model2     0.606267\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_accuracy.sort_values(by=\"avg_performance\", ascending=False).iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I then move on to compare the the precision between different moodels, we find out that random forest has the highest score of precision. However, it is comparingly low in the 0.3873, the models might seem to be working badly in predicting true positive from total positive prediction. However, 0.3873 is much more higher than the proportion of 1 in the total case (0.29), which means that the prediction of the model still make some improvement from the base case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "criterion                   entropy\n",
       "splitter                       best\n",
       "max_depth                        10\n",
       "avg_performance            0.384299\n",
       "performance_temp_model0    0.343526\n",
       "performance_temp_model1    0.425548\n",
       "performance_temp_model2    0.383824\n",
       "Name: 30, dtype: object"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decision_tree_precision.sort_values(by=\"avg_performance\", ascending=False).iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "criterion                      gini\n",
       "n_estimators                     10\n",
       "max_depth                        10\n",
       "avg_performance            0.387322\n",
       "performance_temp_model0    0.346562\n",
       "performance_temp_model1    0.428002\n",
       "performance_temp_model2    0.387402\n",
       "Name: 10, dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest_precision.sort_values(by=\"avg_performance\", ascending=False).iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "kernel                       linear\n",
       "C                                10\n",
       "avg_performance            0.347084\n",
       "performance_temp_model0    0.280285\n",
       "performance_temp_model1    0.391586\n",
       "performance_temp_model2    0.369379\n",
       "Name: 3, dtype: object"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_precision.sort_values(by=\"avg_performance\", ascending=False).iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "penalty                          l1\n",
       "C                                 1\n",
       "avg_performance             0.36985\n",
       "performance_temp_model0    0.335221\n",
       "performance_temp_model1    0.399741\n",
       "performance_temp_model2    0.374587\n",
       "Name: 2, dtype: object"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistics_precision.sort_values(by=\"avg_performance\", ascending=False).iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "metric                     euclidean\n",
       "n_neighbors                       92\n",
       "avg_performance             0.381559\n",
       "performance_temp_model0     0.337887\n",
       "performance_temp_model1     0.420413\n",
       "performance_temp_model2     0.386379\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_precision.sort_values(by=\"avg_performance\", ascending=False).iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then focus on the recall of the models, random forest got the highest score in average performance in recall. The differences between the performance of different models are very low. In general, all of the models do well in predicting true positive from the summation of true positive and false negative. The model is working well in including the unit truely classified as 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "criterion                      gini\n",
       "splitter                     random\n",
       "max_depth                        10\n",
       "avg_performance            0.987956\n",
       "performance_temp_model0    0.981391\n",
       "performance_temp_model1    0.992498\n",
       "performance_temp_model2    0.989978\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decision_tree_recall.sort_values(by=\"avg_performance\", ascending=False).iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "criterion                      gini\n",
       "n_estimators                     15\n",
       "max_depth                        11\n",
       "avg_performance            0.998874\n",
       "performance_temp_model0    0.998459\n",
       "performance_temp_model1    0.999117\n",
       "performance_temp_model2    0.999045\n",
       "Name: 21, dtype: object"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest_recall.sort_values(by=\"avg_performance\", ascending=False).iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "kernel                       linear\n",
       "C                                10\n",
       "avg_performance            0.995618\n",
       "performance_temp_model0    0.993837\n",
       "performance_temp_model1    0.995881\n",
       "performance_temp_model2    0.997136\n",
       "Name: 3, dtype: object"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_recall.sort_values(by=\"avg_performance\", ascending=False).iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "penalty                          l1\n",
       "C                              0.01\n",
       "avg_performance             0.99823\n",
       "performance_temp_model0    0.997629\n",
       "performance_temp_model1     0.99897\n",
       "performance_temp_model2    0.998091\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistics_recall.sort_values(by=\"avg_performance\", ascending=False).iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "metric                     chebyshev\n",
       "n_neighbors                       97\n",
       "avg_performance               0.9985\n",
       "performance_temp_model0     0.998459\n",
       "performance_temp_model1     0.998235\n",
       "performance_temp_model2     0.998807\n",
       "Name: 12, dtype: object"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_recall.sort_values(by=\"avg_performance\", ascending=False).iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then focus on the f1 score of the models which take both precision and recall into account, random forest got the highest score in average performance in f1. The differences between the performance of different models are very low. According to the result be get from the previous model, we know that the score of f1 is dominantly caused by the high recall since the precision is comparing low relatively in all cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "criterion                   entropy\n",
       "splitter                       best\n",
       "max_depth                        10\n",
       "avg_performance            0.492495\n",
       "performance_temp_model0    0.453787\n",
       "performance_temp_model1    0.525931\n",
       "performance_temp_model2    0.497768\n",
       "Name: 30, dtype: object"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decision_tree_f1.sort_values(by=\"avg_performance\", ascending=False).iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "criterion                      gini\n",
       "n_estimators                     15\n",
       "max_depth                        10\n",
       "avg_performance            0.500339\n",
       "performance_temp_model0    0.462003\n",
       "performance_temp_model1    0.536556\n",
       "performance_temp_model2    0.502459\n",
       "Name: 20, dtype: object"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest_f1.sort_values(by=\"avg_performance\", ascending=False).iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "kernel                       linear\n",
       "C                                10\n",
       "avg_performance            0.461323\n",
       "performance_temp_model0    0.413922\n",
       "performance_temp_model1    0.493541\n",
       "performance_temp_model2    0.476505\n",
       "Name: 3, dtype: object"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_f1.sort_values(by=\"avg_performance\", ascending=False).iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "penalty                          l1\n",
       "C                                 1\n",
       "avg_performance            0.476991\n",
       "performance_temp_model0    0.444705\n",
       "performance_temp_model1    0.504953\n",
       "performance_temp_model2    0.481317\n",
       "Name: 2, dtype: object"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistics_f1.sort_values(by=\"avg_performance\", ascending=False).iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "metric                     euclidean\n",
       "n_neighbors                       97\n",
       "avg_performance             0.486483\n",
       "performance_temp_model0     0.446728\n",
       "performance_temp_model1     0.517285\n",
       "performance_temp_model2     0.495435\n",
       "Name: 2, dtype: object"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_f1.sort_values(by=\"avg_performance\", ascending=False).iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we focus on the AUC_ROC score of the models which take both precision and recall into account, random forest got the highest score in average performance in f1. The differences between the performance of different models are very low. According to the result be get from the previous model, we know that the score of f1 is dominantly caused by the high recall since the precision is comparing low relatively in all cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "criterion                   entropy\n",
       "splitter                       best\n",
       "max_depth                        10\n",
       "avg_performance            0.653764\n",
       "performance_temp_model0    0.636967\n",
       "performance_temp_model1    0.662191\n",
       "performance_temp_model2    0.662134\n",
       "Name: 30, dtype: object"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decision_tree_AUC_ROC.sort_values(by=\"avg_performance\", ascending=False).iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "criterion                   entropy\n",
       "n_estimators                     15\n",
       "max_depth                        10\n",
       "avg_performance            0.667928\n",
       "performance_temp_model0    0.655059\n",
       "performance_temp_model1    0.675309\n",
       "performance_temp_model2    0.673415\n",
       "Name: 50, dtype: object"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest_AUC_ROC.sort_values(by=\"avg_performance\", ascending=False).iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "kernel                       linear\n",
       "C                                10\n",
       "avg_performance            0.602857\n",
       "performance_temp_model0    0.542052\n",
       "performance_temp_model1    0.624307\n",
       "performance_temp_model2    0.642213\n",
       "Name: 3, dtype: object"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_AUC_ROC.sort_values(by=\"avg_performance\", ascending=False).iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "penalty                          l1\n",
       "C                               100\n",
       "avg_performance            0.640292\n",
       "performance_temp_model0    0.637662\n",
       "performance_temp_model1    0.637109\n",
       "performance_temp_model2    0.646105\n",
       "Name: 4, dtype: object"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistics_AUC_ROC.sort_values(by=\"avg_performance\", ascending=False).iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "metric                     euclidean\n",
       "n_neighbors                       97\n",
       "avg_performance             0.652853\n",
       "performance_temp_model0     0.638118\n",
       "performance_temp_model1     0.657037\n",
       "performance_temp_model2     0.663404\n",
       "Name: 2, dtype: object"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_AUC_ROC.sort_values(by=\"avg_performance\", ascending=False).iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since in this analysis, we care both the efficiency and inclusiveness of all the models, we will focus on using f1 and AUC_ROC in this case. In order to validate the usage of these models, I apply esembling methods like boosting and bagging for the optimized models we have so far. For f1 score and AUC_ROC score, I will select random_forest model with criterion=entropy, n_estimators=15, and max_depth=10 for the boosting model (since bagging method is already embedded in random forest). Thus, I will imply the optimal logistics model with hyper-parameters penalty==l1 and c==1 for the bagging model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_dt = decision_tree.classifier_settings_rf(criterion=\"entropy\", n_estimators=15, max_depth=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_log = logistic.classifier_settings_log(penalty=\"l1\",C=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By applying the random forest model in boosting model intaking f1 score as evaluation method, the average performance doesn't improve in this case even the n_estimators have been changed. Which is reasonable since boosting tends to work better for linear classifiers like svm and logistics. For the logistics model using bagging method, the performance of f1 has slightly improvement, which is also reasonable since bagging methods works better for variance reduction for models like decision tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do.cross_validate_performance(data_dict, \"boosting\", opt_dt, \"f1\", threshold_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bagging_f1 = do.cross_validate_performance(data_dict, \"bagging\", opt_log, \"f1\", threshold_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>avg_performance</th>\n",
       "      <th>performance_temp_model0</th>\n",
       "      <th>performance_temp_model1</th>\n",
       "      <th>performance_temp_model2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0.476768</td>\n",
       "      <td>0.443639</td>\n",
       "      <td>0.506322</td>\n",
       "      <td>0.480344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>0.476567</td>\n",
       "      <td>0.442857</td>\n",
       "      <td>0.504861</td>\n",
       "      <td>0.481982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>0.476148</td>\n",
       "      <td>0.443213</td>\n",
       "      <td>0.504222</td>\n",
       "      <td>0.481009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  n_estimators  avg_performance  performance_temp_model0  \\\n",
       "0            5         0.476768                 0.443639   \n",
       "1           10         0.476567                 0.442857   \n",
       "2           15         0.476148                 0.443213   \n",
       "\n",
       "   performance_temp_model1  performance_temp_model2  \n",
       "0                 0.506322                 0.480344  \n",
       "1                 0.504861                 0.481982  \n",
       "2                 0.504222                 0.481009  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bagging_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By applying the random forest model in boosting model intaking AUC_ROC score as evaluation method, the average performance doesn't improve in this case even the n_estimators have been changed. We then use logistics model for boosting methods with hyper-parameters penalty==l1 and c==100, but the performance of the model remains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boosting_AUC_ROC = do.cross_validate_performance(data_dict, \"boosting\", opt_dt, \"AUC_ROC\", threshold_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>avg_performance</th>\n",
       "      <th>performance_temp_model0</th>\n",
       "      <th>performance_temp_model1</th>\n",
       "      <th>performance_temp_model2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>0.636191</td>\n",
       "      <td>0.618334</td>\n",
       "      <td>0.640331</td>\n",
       "      <td>0.649907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>0.622903</td>\n",
       "      <td>0.605185</td>\n",
       "      <td>0.627225</td>\n",
       "      <td>0.636298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>150</td>\n",
       "      <td>0.614660</td>\n",
       "      <td>0.598672</td>\n",
       "      <td>0.617899</td>\n",
       "      <td>0.627410</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  n_estimators  avg_performance  performance_temp_model0  \\\n",
       "0           50         0.636191                 0.618334   \n",
       "1          100         0.622903                 0.605185   \n",
       "2          150         0.614660                 0.598672   \n",
       "\n",
       "   performance_temp_model1  performance_temp_model2  \n",
       "0                 0.640331                 0.649907  \n",
       "1                 0.627225                 0.636298  \n",
       "2                 0.617899                 0.627410  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boosting_AUC_ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_log = logistic.classifier_settings_log(penalty=\"l1\",C=100, n_jobs=1)\n",
    "boosting_AUC_ROC_log = do.cross_validate_performance(data_dict, \"boosting\", opt_log, \"AUC_ROC\", threshold_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>avg_performance</th>\n",
       "      <th>performance_temp_model0</th>\n",
       "      <th>performance_temp_model1</th>\n",
       "      <th>performance_temp_model2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>0.61632</td>\n",
       "      <td>0.615028</td>\n",
       "      <td>0.618514</td>\n",
       "      <td>0.615420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>0.61632</td>\n",
       "      <td>0.615028</td>\n",
       "      <td>0.618513</td>\n",
       "      <td>0.615420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>150</td>\n",
       "      <td>0.61632</td>\n",
       "      <td>0.615028</td>\n",
       "      <td>0.618513</td>\n",
       "      <td>0.615419</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  n_estimators  avg_performance  performance_temp_model0  \\\n",
       "0           50          0.61632                 0.615028   \n",
       "1          100          0.61632                 0.615028   \n",
       "2          150          0.61632                 0.615028   \n",
       "\n",
       "   performance_temp_model1  performance_temp_model2  \n",
       "0                 0.618514                 0.615420  \n",
       "1                 0.618513                 0.615420  \n",
       "2                 0.618513                 0.615419  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boosting_AUC_ROC_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main purpose of the analysis is to target the projects on the donorchoose which contain higher risks of not being funded in 60 days after they were posted. First of all, I define the classifier by classifing the projects which are not funded in 60 days after they were posted as 1. In total, we have arround 29% of our data be classified as 1. At this level, we are not arguing that the samples are inbalance. The data contains some missing values in categorical features which may influence the operation of the machine learning models. The problem may be solved by filling in the most frequent values in the given features. After transforming categorical features to binary and scaling continuous variables, there are in total 92 usable features in the dataset. I then apply feature selection methods to choose 30 features which contain the 30 highest variances in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['resource_type==Technology',\n",
       " 'eligible_double_your_impact_match==t',\n",
       " 'eligible_double_your_impact_match==f',\n",
       " 'total_price_including_optional_support',\n",
       " 'resource_type==Supplies',\n",
       " 'resource_type==Books',\n",
       " 'poverty_level==highest poverty',\n",
       " 'primary_focus_area==Literacy & Language',\n",
       " 'primary_focus_area==Music & The Arts',\n",
       " 'primary_focus_subject==Environmental Science',\n",
       " 'poverty_level==high poverty',\n",
       " 'primary_focus_area==Math & Science',\n",
       " 'primary_focus_subject==Music',\n",
       " 'resource_type==Trips',\n",
       " 'secondary_focus_area==Music & The Arts',\n",
       " 'poverty_level==moderate poverty',\n",
       " 'primary_focus_subject==Visual Arts',\n",
       " 'primary_focus_subject==Literature & Writing',\n",
       " 'primary_focus_subject==Health & Life Science',\n",
       " 'secondary_focus_subject==Mathematics',\n",
       " 'primary_focus_subject==Literacy',\n",
       " 'primary_focus_subject==College & Career Prep',\n",
       " 'secondary_focus_subject==Performing Arts',\n",
       " 'secondary_focus_subject==Other',\n",
       " 'primary_focus_subject==Other',\n",
       " 'school_magnet==t',\n",
       " 'school_magnet==f',\n",
       " 'school_charter==t',\n",
       " 'school_charter==f',\n",
       " 'secondary_focus_subject==Health & Life Science']"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Kfeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the above table, we might observe that characteristics like whether the project has technological resource type, whether the project was eligible for a 50% off offer by a corporate partner, the total price of the support, poverty level and focusing area are potentially influential to the prediction of the models\n",
    "\n",
    "For the training part of the analysis, the cross_validate_performance function in do.py file provides a general pipeline to evaluate the performance of each models with different hyper-parameter passing in. The function will automatically find the best threshold which produce the highest score of the given evaluation methods. The list of threshold I am testing with is the percentile [0.01, 0.02, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5] in the probability distribution of the predicted probabilities. The model also take cross-validated method into account and return the individual performances and average performance for the subsets of train-test split with given combination of hyper-parameters. In this case we will apply rolling window strategy as the cross-validation method for temporal data with time unit of 6 months.\n",
    "\n",
    "First of all, we compare the evaluation method using accuracy with different machine learning models and take the combination with the highest performance, and find out that knn has the highest accuracy score. However, accuracy is not a appropriate measurement in our analysis since it does not have a clear distinguision on where the accuracy comes from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "metric                     euclidean\n",
       "n_neighbors                       92\n",
       "avg_performance             0.602392\n",
       "performance_temp_model0     0.589835\n",
       "performance_temp_model1     0.611073\n",
       "performance_temp_model2     0.606267\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_accuracy.sort_values(by=\"avg_performance\", ascending=False).iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Secondly, I compare the the precision between different moodels, and find out that random forest has the highest score of precision. The models might seem to be working badly in predicting true positive from total positive prediction with the score of 0.3873. However, 0.3873 is much more higher than the proportion of 1 in the total case (0.29), which means that the prediction of the model still make some improvement from the base case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "criterion                      gini\n",
       "n_estimators                     10\n",
       "max_depth                        10\n",
       "avg_performance            0.387322\n",
       "performance_temp_model0    0.346562\n",
       "performance_temp_model1    0.428002\n",
       "performance_temp_model2    0.387402\n",
       "Name: 10, dtype: object"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest_precision.sort_values(by=\"avg_performance\", ascending=False).iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then focus on the recall of the models, random forest got the highest score in average performance in recall. The differences between the performance of different models are very low. In general, all of the models do well in predicting true positive from the summation of true positive and false negative. The model is working well in including the unit truely classified as 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "criterion                      gini\n",
       "n_estimators                     15\n",
       "max_depth                        11\n",
       "avg_performance            0.998874\n",
       "performance_temp_model0    0.998459\n",
       "performance_temp_model1    0.999117\n",
       "performance_temp_model2    0.999045\n",
       "Name: 21, dtype: object"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest_recall.sort_values(by=\"avg_performance\", ascending=False).iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then focus on the f1 score and AUC_ROC of the models which take both precision and recall into account, random forest got the highest score in average performance in both f1 and AUC_ROC. The differences between the performance of different models are very low. According to the result be get from the previous model, we know that the score of f1 and AUC_ROC are dominantly caused by the high recall since the precision is comparing low relatively in all cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "criterion                      gini\n",
       "n_estimators                     15\n",
       "max_depth                        10\n",
       "avg_performance            0.500339\n",
       "performance_temp_model0    0.462003\n",
       "performance_temp_model1    0.536556\n",
       "performance_temp_model2    0.502459\n",
       "Name: 20, dtype: object"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest_f1.sort_values(by=\"avg_performance\", ascending=False).iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "criterion                   entropy\n",
       "n_estimators                     15\n",
       "max_depth                        10\n",
       "avg_performance            0.667928\n",
       "performance_temp_model0    0.655059\n",
       "performance_temp_model1    0.675309\n",
       "performance_temp_model2    0.673415\n",
       "Name: 50, dtype: object"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest_AUC_ROC.sort_values(by=\"avg_performance\", ascending=False).iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In those tables above, we might observe the fluctuations over times after we include more time interval for training subsets. Thus, we use the average performance from the temporal splitted datasets and conclude that random forest model with criterion=entropy, n_estimators=15, and max_depth=10 for hyper-parameters perform the best in the prediction of the high risk project which might not be funded in 60 days. I also try boosting method on random forest model, but the result is quite similar to the original model which is reasonable since boosting method is working better on linear classifiers like svm and logistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_AUC_ROC = do.cross_validate_performance(data_dict, \"random_forest\", [], \"AUC_ROC\", [0.05])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "criterion                   entropy\n",
       "n_estimators                     15\n",
       "max_depth                        10\n",
       "avg_performance            0.669093\n",
       "performance_temp_model0    0.656031\n",
       "performance_temp_model1    0.677662\n",
       "performance_temp_model2    0.673584\n",
       "Name: 50, dtype: object"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest_AUC_ROC.sort_values(by=\"avg_performance\", ascending=False).iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we care about the 5% of project population which contain the highest risk of not receiving funds, we re-run the random forest model by setting the threshold to the percentile of 5 in the predicted probability array and discover that the performance of AUC_ROC is similar to the overall best model with multiple threshold. I will recommend to deploy this model as the classifier for predicting the high risk projects in donorchoose. The distribution of the predicted probability and precision recall curve of the optimal model is presented below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = data_dict[3][0], data_dict[3][1], data_dict[3][2], data_dict[3][3]\n",
    "opt_dt = decision_tree.classifier_settings_rf(criterion=\"entropy\", n_estimators=15, max_depth=10)\n",
    "ypredp = decision_tree.train_random_forest(X_train, y_train, X_test, opt_dt)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mean = 0.5, count = 44167'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eva.predp_distribution(ypredp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eva.depict_precision_recall_curve(y_test, ypredp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py3.5]",
   "language": "python",
   "name": "conda-env-py3.5-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import date\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "\n",
    "import feature_generation as fg\n",
    "import imputation as imp\n",
    "import evaluation as eva\n",
    "import train_test_split as tts\n",
    "import clf_define as clfd\n",
    "import data_util as util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = util.read_csv_data(r\"projects_2012_2013.csv\", {}, parse_dates=['date_posted', 'datefullyfunded'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, we will like to define our features and classifiers in the dataframe. In order to maintain the as much patterns as possible, we will only drop the columns with ids which include too much distinguish categories (more than 51) and information like logitude and latitude which can be categorized better using city and state. The number 51 is selected due to the number of state categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "preserved_columns = []\n",
    "for column in data.columns:\n",
    "    if (data[column].dtype=='O') and (len(data[column].unique())<=51):\n",
    "        preserved_columns.append(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['school_state', 'school_metro', 'school_charter', 'school_magnet', 'teacher_prefix', 'primary_focus_subject', 'primary_focus_area', 'secondary_focus_subject', 'secondary_focus_area', 'resource_type', 'poverty_level', 'grade_level', 'eligible_double_your_impact_match']\n"
     ]
    }
   ],
   "source": [
    "print(preserved_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_features = ['total_price_including_optional_support', 'students_reached']\n",
    "categorical_features = set(preserved_columns) - set(continuous_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'school_metro', 'grade_level', 'secondary_focus_area', 'poverty_level', 'secondary_focus_subject', 'eligible_double_your_impact_match', 'school_state', 'teacher_prefix', 'school_magnet', 'school_charter', 'primary_focus_subject', 'primary_focus_area', 'resource_type'}\n"
     ]
    }
   ],
   "source": [
    "print(categorical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_price_including_optional_support</th>\n",
       "      <th>students_reached</th>\n",
       "      <th>school_metro</th>\n",
       "      <th>grade_level</th>\n",
       "      <th>secondary_focus_area</th>\n",
       "      <th>poverty_level</th>\n",
       "      <th>secondary_focus_subject</th>\n",
       "      <th>eligible_double_your_impact_match</th>\n",
       "      <th>school_state</th>\n",
       "      <th>teacher_prefix</th>\n",
       "      <th>school_magnet</th>\n",
       "      <th>school_charter</th>\n",
       "      <th>primary_focus_subject</th>\n",
       "      <th>primary_focus_area</th>\n",
       "      <th>resource_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1498.61</td>\n",
       "      <td>31.0</td>\n",
       "      <td>urban</td>\n",
       "      <td>Grades PreK-2</td>\n",
       "      <td>Music &amp; The Arts</td>\n",
       "      <td>highest poverty</td>\n",
       "      <td>Visual Arts</td>\n",
       "      <td>f</td>\n",
       "      <td>IL</td>\n",
       "      <td>Mrs.</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>Mathematics</td>\n",
       "      <td>Math &amp; Science</td>\n",
       "      <td>Supplies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>282.47</td>\n",
       "      <td>28.0</td>\n",
       "      <td>urban</td>\n",
       "      <td>Grades 3-5</td>\n",
       "      <td>Literacy &amp; Language</td>\n",
       "      <td>highest poverty</td>\n",
       "      <td>Literature &amp; Writing</td>\n",
       "      <td>t</td>\n",
       "      <td>CA</td>\n",
       "      <td>Mrs.</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>Civics &amp; Government</td>\n",
       "      <td>History &amp; Civics</td>\n",
       "      <td>Books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1012.38</td>\n",
       "      <td>56.0</td>\n",
       "      <td>urban</td>\n",
       "      <td>Grades 3-5</td>\n",
       "      <td>History &amp; Civics</td>\n",
       "      <td>high poverty</td>\n",
       "      <td>Social Sciences</td>\n",
       "      <td>f</td>\n",
       "      <td>CA</td>\n",
       "      <td>Ms.</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>Literacy</td>\n",
       "      <td>Literacy &amp; Language</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>175.33</td>\n",
       "      <td>23.0</td>\n",
       "      <td>urban</td>\n",
       "      <td>Grades PreK-2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>high poverty</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>NY</td>\n",
       "      <td>Ms.</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>Literacy</td>\n",
       "      <td>Literacy &amp; Language</td>\n",
       "      <td>Books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3591.11</td>\n",
       "      <td>150.0</td>\n",
       "      <td>suburban</td>\n",
       "      <td>Grades PreK-2</td>\n",
       "      <td>Literacy &amp; Language</td>\n",
       "      <td>high poverty</td>\n",
       "      <td>Literature &amp; Writing</td>\n",
       "      <td>f</td>\n",
       "      <td>NY</td>\n",
       "      <td>Mrs.</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>Literacy</td>\n",
       "      <td>Literacy &amp; Language</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   total_price_including_optional_support  students_reached school_metro  \\\n",
       "0                                 1498.61              31.0        urban   \n",
       "1                                  282.47              28.0        urban   \n",
       "2                                 1012.38              56.0        urban   \n",
       "3                                  175.33              23.0        urban   \n",
       "4                                 3591.11             150.0     suburban   \n",
       "\n",
       "     grade_level secondary_focus_area    poverty_level  \\\n",
       "0  Grades PreK-2     Music & The Arts  highest poverty   \n",
       "1     Grades 3-5  Literacy & Language  highest poverty   \n",
       "2     Grades 3-5     History & Civics     high poverty   \n",
       "3  Grades PreK-2                  NaN     high poverty   \n",
       "4  Grades PreK-2  Literacy & Language     high poverty   \n",
       "\n",
       "  secondary_focus_subject eligible_double_your_impact_match school_state  \\\n",
       "0             Visual Arts                                 f           IL   \n",
       "1    Literature & Writing                                 t           CA   \n",
       "2         Social Sciences                                 f           CA   \n",
       "3                     NaN                                 f           NY   \n",
       "4    Literature & Writing                                 f           NY   \n",
       "\n",
       "  teacher_prefix school_magnet school_charter primary_focus_subject  \\\n",
       "0           Mrs.             f              f           Mathematics   \n",
       "1           Mrs.             f              f   Civics & Government   \n",
       "2            Ms.             f              f              Literacy   \n",
       "3            Ms.             t              f              Literacy   \n",
       "4           Mrs.             f              f              Literacy   \n",
       "\n",
       "    primary_focus_area resource_type  \n",
       "0       Math & Science      Supplies  \n",
       "1     History & Civics         Books  \n",
       "2  Literacy & Language    Technology  \n",
       "3  Literacy & Language         Books  \n",
       "4  Literacy & Language    Technology  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[continuous_features + list(categorical_features)].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We label 1 to the project which are not funded in 60 days right after they are posted, and label 0 to those who are funded in 60 days right after it is posted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['duration'] = data[\"datefullyfunded\"] - data[\"date_posted\"]\n",
    "data['classifier'] =  np.where(data['duration'] > pd.Timedelta('60 days'), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    1\n",
       "3    0\n",
       "4    1\n",
       "Name: classifier, dtype: int32"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = \"classifier\"\n",
    "data[\"classifier\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then move on to split the dataframe to train and test sets with rolling windows stratefy in this case. I split the dataframe with time unit of half years cutoff which is at date 6/30 and 12/31. For every training data set, there will remain 60 days gap for the result (label) of the outcome (classifier) to be observed. The testing set will be set as half year (might be shorter in the last test set) right after the gap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "half_year_stamp = [(1,1), (7,1)]\n",
    "start_date = pd.Timestamp('2012-01-01 00:00:00')\n",
    "end_date = pd.Timestamp('2014-01-01 00:00:00')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "time_cutoff lists includes the start date, one day after the end dates and other cutoff dates, time interval will be defined as the date between them (including the lower but not include the upper bound)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Timestamp('2012-01-01 00:00:00'), Timestamp('2012-07-01 00:00:00'), Timestamp('2013-01-01 00:00:00'), Timestamp('2013-07-01 00:00:00'), Timestamp('2014-01-01 00:00:00')]\n"
     ]
    }
   ],
   "source": [
    "time_cutoffs = tts.gen_time_cuts(start_date, end_date, half_year_stamp)\n",
    "print(sorted(time_cutoffs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I use define_time_variables to create the indicators for rolling window split in this case, taking waiting times (60 days) into account. All train dataframe starts in 2012-01-01 but the testing data starts at 2012-07-01 + (60 days), 2013-01-01 + (60 days), 2013-07-01 + (60 days) respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = tts.define_time_variables(data, pd.Timedelta('183 days'), pd.Timedelta('60 days'), \"date_posted\", \"datefullyfunded\", start_date, end_date, half_year_stamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69180   2012-01-01\n",
       "32005   2012-01-01\n",
       "38220   2012-01-01\n",
       "74297   2012-01-01\n",
       "21950   2012-01-01\n",
       "Name: date_posted, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data[\"tmp_label0\"] == \"train\"][\"date_posted\"].sort_values(ascending=True).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16332    2012-08-30\n",
       "60107    2012-08-30\n",
       "71880    2012-08-30\n",
       "107093   2012-08-30\n",
       "107156   2012-08-30\n",
       "Name: date_posted, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data[\"tmp_label0\"] == \"test\"][\"date_posted\"].sort_values(ascending=True).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72487    2012-01-01\n",
       "63421    2012-01-01\n",
       "117377   2012-01-01\n",
       "62941    2012-01-01\n",
       "117198   2012-01-01\n",
       "Name: date_posted, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data[\"tmp_label1\"] == \"train\"][\"date_posted\"].sort_values(ascending=True).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "121525   2013-03-02\n",
       "37673    2013-03-02\n",
       "3158     2013-03-02\n",
       "108509   2013-03-02\n",
       "30275    2013-03-02\n",
       "Name: date_posted, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data[\"tmp_label1\"] == \"test\"][\"date_posted\"].sort_values(ascending=True).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63675    2012-01-01\n",
       "114946   2012-01-01\n",
       "48094    2012-01-01\n",
       "50966    2012-01-01\n",
       "107459   2012-01-01\n",
       "Name: date_posted, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data[\"tmp_label2\"] == \"train\"][\"date_posted\"].sort_values(ascending=True).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66491    2013-08-30\n",
       "121728   2013-08-30\n",
       "15134    2013-08-30\n",
       "111442   2013-08-30\n",
       "93247    2013-08-30\n",
       "Name: date_posted, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data[\"tmp_label2\"] == \"test\"][\"date_posted\"].sort_values(ascending=True).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is then be splitted according to the time_split_indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_split_indicators = [\"tmp_label0\", \"tmp_label1\", \"tmp_label2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = tts.rolling_window_split(data, time_split_indicators, list(categorical_features) + continuous_features, classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We than move on to the imputation of missing values in the data of each sub set, we used the trained infromation in the training dataframe is used it in the transformation in the corresponding test dataframe. We will used different strategies with different missing values in the dataframe. For the categorical variables, we will use a \"unknown\" category to replace the unknown values. (Using fill_unknown) For the continuous variable, we will use the group mean of the training data to impute both training and testing dataframe. (Using fill_na_mean) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe several missing values in the given dataframe after rolling window split, we do not want to include classifier in the imputation since labeling unknown classification will be problematic with distribution taht we are not sure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing in training tmp_label2\n",
      "{'school_metro': (9412, 80809), 'grade_level': (3, 80809), 'poverty_level': (0, 80809), 'secondary_focus_subject': (26340, 80809), 'students_reached': (59, 80809), 'school_state': (0, 80809), 'total_price_including_optional_support': (0, 80809), 'teacher_prefix': (0, 80809), 'school_magnet': (0, 80809), 'school_charter': (0, 80809), 'primary_focus_area': (15, 80809), 'resource_type': (17, 80809), 'primary_focus_subject': (15, 80809), 'secondary_focus_area': (26340, 80809), 'eligible_double_your_impact_match': (0, 80809)}\n",
      "missing in testing tmp_label2\n",
      "{'school_metro': (4250, 32994), 'grade_level': (0, 32994), 'poverty_level': (0, 32994), 'secondary_focus_subject': (10442, 32994), 'students_reached': (0, 32994), 'school_state': (0, 32994), 'total_price_including_optional_support': (0, 32994), 'teacher_prefix': (0, 32994), 'school_magnet': (0, 32994), 'school_charter': (0, 32994), 'primary_focus_area': (0, 32994), 'resource_type': (0, 32994), 'primary_focus_subject': (0, 32994), 'secondary_focus_area': (10442, 32994), 'eligible_double_your_impact_match': (0, 32994)}\n",
      "           \n",
      "missing in training tmp_label1\n",
      "{'school_metro': (6615, 59224), 'grade_level': (1, 59224), 'poverty_level': (0, 59224), 'secondary_focus_subject': (19574, 59224), 'students_reached': (4, 59224), 'school_state': (0, 59224), 'total_price_including_optional_support': (0, 59224), 'teacher_prefix': (0, 59224), 'school_magnet': (0, 59224), 'school_charter': (0, 59224), 'primary_focus_area': (2, 59224), 'resource_type': (2, 59224), 'primary_focus_subject': (2, 59224), 'secondary_focus_area': (19574, 59224), 'eligible_double_your_impact_match': (0, 59224)}\n",
      "missing in testing tmp_label1\n",
      "{'school_metro': (3337, 24857), 'grade_level': (0, 24857), 'poverty_level': (0, 24857), 'secondary_focus_subject': (8033, 24857), 'students_reached': (32, 24857), 'school_state': (0, 24857), 'total_price_including_optional_support': (0, 24857), 'teacher_prefix': (0, 24857), 'school_magnet': (0, 24857), 'school_charter': (0, 24857), 'primary_focus_area': (9, 24857), 'resource_type': (10, 24857), 'primary_focus_subject': (9, 24857), 'secondary_focus_area': (8033, 24857), 'eligible_double_your_impact_match': (0, 24857)}\n",
      "           \n",
      "missing in training tmp_label0\n",
      "{'school_metro': (2643, 26386), 'grade_level': (1, 26386), 'poverty_level': (0, 26386), 'secondary_focus_subject': (8524, 26386), 'students_reached': (4, 26386), 'school_state': (0, 26386), 'total_price_including_optional_support': (0, 26386), 'teacher_prefix': (0, 26386), 'school_magnet': (0, 26386), 'school_charter': (0, 26386), 'primary_focus_area': (2, 26386), 'resource_type': (2, 26386), 'primary_focus_subject': (2, 26386), 'secondary_focus_area': (8524, 26386), 'eligible_double_your_impact_match': (0, 26386)}\n",
      "missing in testing tmp_label0\n",
      "{'school_metro': (4015, 33357), 'grade_level': (2, 33357), 'poverty_level': (0, 33357), 'secondary_focus_subject': (11045, 33357), 'students_reached': (22, 33357), 'school_state': (0, 33357), 'total_price_including_optional_support': (0, 33357), 'teacher_prefix': (0, 33357), 'school_magnet': (0, 33357), 'school_charter': (0, 33357), 'primary_focus_area': (4, 33357), 'resource_type': (5, 33357), 'primary_focus_subject': (4, 33357), 'secondary_focus_area': (11045, 33357), 'eligible_double_your_impact_match': (0, 33357)}\n",
      "           \n"
     ]
    }
   ],
   "source": [
    "for idx, dat in data_dict.items():\n",
    "    train_X, train_y, test_X, test_y = dat\n",
    "    print(\"missing in training \" + idx)\n",
    "    print(imp.summarize_missing_values(train_X))\n",
    "    print(\"missing in testing \" + idx)\n",
    "    print(imp.summarize_missing_values(test_X))\n",
    "    print(\"           \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_data_dict = {}\n",
    "for idx, dat in data_dict.items():\n",
    "    train_X, train_y, test_X, test_y = dat\n",
    "    train_X, test_X = imp.fill_na_mean(train_X, test_X, continuous_features)\n",
    "    train_X, test_X = imp.fill_unknown(train_X, test_X, categorical_features)\n",
    "    imp_data_dict[idx] = [train_X, train_y, test_X, test_y]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that after the imputation the new_data_dict contains no missing values in the training and testing subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing in training tmp_label0\n",
      "{'school_metro': (0, 26386), 'grade_level': (0, 26386), 'poverty_level': (0, 26386), 'secondary_focus_subject': (0, 26386), 'students_reached': (0, 26386), 'school_state': (0, 26386), 'total_price_including_optional_support': (0, 26386), 'teacher_prefix': (0, 26386), 'school_magnet': (0, 26386), 'school_charter': (0, 26386), 'primary_focus_area': (0, 26386), 'resource_type': (0, 26386), 'primary_focus_subject': (0, 26386), 'secondary_focus_area': (0, 26386), 'eligible_double_your_impact_match': (0, 26386)}\n",
      "missing in testing tmp_label0\n",
      "{'school_metro': (0, 33357), 'grade_level': (0, 33357), 'poverty_level': (0, 33357), 'secondary_focus_subject': (0, 33357), 'students_reached': (0, 33357), 'school_state': (0, 33357), 'total_price_including_optional_support': (0, 33357), 'teacher_prefix': (0, 33357), 'school_magnet': (0, 33357), 'school_charter': (0, 33357), 'primary_focus_area': (0, 33357), 'resource_type': (0, 33357), 'primary_focus_subject': (0, 33357), 'secondary_focus_area': (0, 33357), 'eligible_double_your_impact_match': (0, 33357)}\n",
      "           \n",
      "missing in training tmp_label1\n",
      "{'school_metro': (0, 59224), 'grade_level': (0, 59224), 'poverty_level': (0, 59224), 'secondary_focus_subject': (0, 59224), 'students_reached': (0, 59224), 'school_state': (0, 59224), 'total_price_including_optional_support': (0, 59224), 'teacher_prefix': (0, 59224), 'school_magnet': (0, 59224), 'school_charter': (0, 59224), 'primary_focus_area': (0, 59224), 'resource_type': (0, 59224), 'primary_focus_subject': (0, 59224), 'secondary_focus_area': (0, 59224), 'eligible_double_your_impact_match': (0, 59224)}\n",
      "missing in testing tmp_label1\n",
      "{'school_metro': (0, 24857), 'grade_level': (0, 24857), 'poverty_level': (0, 24857), 'secondary_focus_subject': (0, 24857), 'students_reached': (0, 24857), 'school_state': (0, 24857), 'total_price_including_optional_support': (0, 24857), 'teacher_prefix': (0, 24857), 'school_magnet': (0, 24857), 'school_charter': (0, 24857), 'primary_focus_area': (0, 24857), 'resource_type': (0, 24857), 'primary_focus_subject': (0, 24857), 'secondary_focus_area': (0, 24857), 'eligible_double_your_impact_match': (0, 24857)}\n",
      "           \n",
      "missing in training tmp_label2\n",
      "{'school_metro': (0, 80809), 'grade_level': (0, 80809), 'poverty_level': (0, 80809), 'secondary_focus_subject': (0, 80809), 'students_reached': (0, 80809), 'school_state': (0, 80809), 'total_price_including_optional_support': (0, 80809), 'teacher_prefix': (0, 80809), 'school_magnet': (0, 80809), 'school_charter': (0, 80809), 'primary_focus_area': (0, 80809), 'resource_type': (0, 80809), 'primary_focus_subject': (0, 80809), 'secondary_focus_area': (0, 80809), 'eligible_double_your_impact_match': (0, 80809)}\n",
      "missing in testing tmp_label2\n",
      "{'school_metro': (0, 32994), 'grade_level': (0, 32994), 'poverty_level': (0, 32994), 'secondary_focus_subject': (0, 32994), 'students_reached': (0, 32994), 'school_state': (0, 32994), 'total_price_including_optional_support': (0, 32994), 'teacher_prefix': (0, 32994), 'school_magnet': (0, 32994), 'school_charter': (0, 32994), 'primary_focus_area': (0, 32994), 'resource_type': (0, 32994), 'primary_focus_subject': (0, 32994), 'secondary_focus_area': (0, 32994), 'eligible_double_your_impact_match': (0, 32994)}\n",
      "           \n"
     ]
    }
   ],
   "source": [
    "for idx, dat in imp_data_dict.items():\n",
    "    train_X, train_y, test_X, test_y = dat\n",
    "    print(\"missing in training \" + idx)\n",
    "    print(imp.summarize_missing_values(train_X))\n",
    "    print(\"missing in testing \" + idx)\n",
    "    print(imp.summarize_missing_values(test_X))\n",
    "    print(\"           \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After I impute the missing values, I move on to feature generations. In this process, the features generated in the training dataframe have to be consistant to the features in testing dataframe. All categorical variables in the selected features will be transformed to binary features and all continuous variables will be transformed to scaled continuous using MaxMinScale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_data_dict = {}\n",
    "for idx, dat in imp_data_dict.items():\n",
    "    train_X, train_y, test_X, test_y = dat\n",
    "    train_X, test_X = fg.min_max_transformation(train_X, test_X, continuous_features)\n",
    "    ft_data_dict[idx] = [train_X, train_y, test_X, test_y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_data_dict2 = {}\n",
    "for idx, dat in ft_data_dict.items():\n",
    "    train_X, train_y, test_X, test_y = dat\n",
    "    for cat_column in categorical_features:\n",
    "        train_X, test_X = fg.category_to_binary(train_X, test_X, cat_column, 3)\n",
    "    ft_data_dict2[idx] = [train_X, train_y, test_X, test_y]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then define the final dictionary of data using for machine learning pipeline as ft_data_dict2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = ft_data_dict2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, I will select the largest training subset with its corresponding testing subset after the imputation and feature generation. Best performed random forest model will also be used to determine the riskiest 5% cases for the following assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = data_dict[\"tmp_label2\"][0], data_dict[\"tmp_label2\"][1], data_dict[\"tmp_label2\"][2], data_dict[\"tmp_label2\"][3]\n",
    "rand = clfd.RandomForestClassifier()\n",
    "rand.set_params(**{'min_samples_split': 10, 'n_jobs': 2, 'class_weight': None, 'random_state': None, 'min_impurity_decrease': 0.0, 'oob_score': False, 'n_estimators': 100, 'verbose': 0, 'criterion': 'gini', 'max_leaf_nodes': None, 'max_depth': 50, 'min_samples_leaf': 1, 'min_impurity_split': None, 'warm_start': False, 'min_weight_fraction_leaf': 0.0, 'max_features': 'sqrt', 'bootstrap': True})\n",
    "model = rand.fit(X_train, y_train)\n",
    "y_predp = model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_pickle(\"test_k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test.reset_index(drop=True)\n",
    "y_predp = pd.DataFrame(y_predp[:,1], columns=[\"y_predp\"])\n",
    "y_predp = y_predp.reset_index(drop=True)\n",
    "full = X_test.join(y_predp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sub_n = 0.05 * full.shape[0] #sub_n = 1650\n",
    "sub_df = full.sort_values(by=\"y_predp\", ascending=False)[:1650]\n",
    "sub_df.drop([\"y_predp\"], axis=1)\n",
    "sub_df = sub_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df.to_pickle(\"sub_test_k\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We finally get the subset with only 5% of the testing cases which are the most riskiest not to be funded in 60 days"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py3.5]",
   "language": "python",
   "name": "conda-env-py3.5-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
